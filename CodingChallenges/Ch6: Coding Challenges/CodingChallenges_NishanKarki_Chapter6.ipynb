{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e026ee5",
   "metadata": {},
   "source": [
    "# Coding Challenges: Chapter 6\n",
    "Nishan Karki\n",
    "BINF 3360\n",
    "Computational Biology\n",
    "Date: 04/14/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e0d383",
   "metadata": {},
   "source": [
    "# 6.6 STEP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48639a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.29 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from scipy.spatial import distance\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c85eb04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "2\n",
      "1331\n",
      "3.1 15.3\n",
      "33.7 0.7\n",
      "24.2 20.3\n",
      "13.4 0.0\n",
      "0.4 33.1\n",
      "0.0 1.7\n"
     ]
    }
   ],
   "source": [
    "def FarthestFirstTraversal(data, k, n, m):\n",
    "    def dist_ct(p1):\n",
    "        return min([distance.euclidean(p1,centre) for centre in all_centers ])\n",
    "\n",
    "    all_centers = []\n",
    "    f_centers = data[0]\n",
    "    all_centers.append(f_centers)\n",
    "\n",
    "    while len(all_centers) < (k):\n",
    "#         print(len(all_centers))\n",
    "        b_center = []\n",
    "        m_dist = -1\n",
    "#         for e1 in all_centers:\n",
    "#             a = e1\n",
    "#             print('---')\n",
    "#             print(a)\n",
    "#             print('---')\n",
    "#         all_centers.append(max([dist_ct(b) for b in data]))\n",
    "        for b in data:\n",
    "                if (dist_ct(b) > m_dist):\n",
    "                    m_dist = dist_ct(b)\n",
    "                    b_center = b\n",
    "                \n",
    "        all_centers.append(b_center)\n",
    "     \n",
    "    return all_centers\n",
    "        \n",
    "\n",
    "def main():\n",
    "    \n",
    "    with open('/Users/nises/Downloads/dataset_604537_2.txt', 'r') as f:\n",
    "        km = f.readline().strip().split(' ')\n",
    "        mat_a = [[float(num) for num in line.strip().split(' ')] for line in f]\n",
    "        \n",
    "    k = int(km[0])\n",
    "    m = int(km[1])\n",
    "    n = (len(mat_a))\n",
    "    print(k)\n",
    "    print(m)\n",
    "    print(n)\n",
    "#     mat_a = np.asarray(m_row)\n",
    "#     print(mat_a)\n",
    "#     print(m_row)\n",
    "    cet = (FarthestFirstTraversal(mat_a, k, n, m))\n",
    "    for center in cet:\n",
    "        print(\" \".join(map(str, center)))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2909f2",
   "metadata": {},
   "source": [
    "# 6.7 STEP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59eac7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "1173\n",
      "31.994953111679475\n"
     ]
    }
   ],
   "source": [
    "def SquaredErrorDistortion(data, k, n, m, all_centers):\n",
    "    \n",
    "    def distance(p1,p2):\n",
    "        return sum([(p1[i]-p2[i])**2 for i in range(len(p1))])\n",
    "\n",
    "#     def dist_ct(p1):\n",
    "#         return min([distance.euclidean(p1,centre) for centre in all_centers ])\n",
    "    \n",
    "    def dist_ct(p1):\n",
    "        return min([distance(p1,centre) for centre in all_centers ])\n",
    "     \n",
    "    return sum([dist_ct(e1) for e1 in data])/ n\n",
    "        \n",
    "\n",
    "def main():\n",
    "    \n",
    "    with open('/Users/nises/Downloads/dataset_604538_3.txt', 'r') as f:\n",
    "        km = f.readline().strip().split(' ')\n",
    "        k = int(km[0])\n",
    "        data = [[float(num) for num in line.strip().split(' ')] for line in f]\n",
    "        centers = data[0:k]\n",
    "        mat_a = data[k:]\n",
    "\n",
    "        \n",
    "    k = int(km[0])\n",
    "    m = int(km[1])\n",
    "    n = (len(mat_a))\n",
    "    \n",
    "    print(k)\n",
    "    print(m)\n",
    "    print(n)\n",
    "#     print(centers)\n",
    "#     print(mat_a)\n",
    "    \n",
    "    SED = (SquaredErrorDistortion(mat_a, k, n, m, centers))\n",
    "    print(SED)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb8f0f",
   "metadata": {},
   "source": [
    "# 6.8 STEP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b0dcc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "1419\n",
      "7.156378600823048 17.858847736625496 7.482304526748974 7.179423868312757\n",
      "6.718503937007873 5.7248031496063 16.965748031496062 6.207086614173225\n",
      "16.50275590551181 6.379133858267717 6.507874015748035 7.551968503937008\n",
      "5.041031941031942 5.365356265356262 4.792874692874692 4.360442260442262\n",
      "5.311494252873563 6.711494252873567 6.22222222222222 15.695785440613035\n"
     ]
    }
   ],
   "source": [
    "def dist_eu(p1, all_centers):\n",
    "    return min([distance.euclidean(p1,centre) for centre in all_centers ])\n",
    "\n",
    "def pt_center(p1, all_centers):\n",
    "    min_dist = float(\"Inf\")\n",
    "    for center in all_centers:\n",
    "        if distance.euclidean(p1,center)< min_dist:\n",
    "            min_dist = distance.euclidean(p1,center)\n",
    "            a_center = center\n",
    "    return a_center\n",
    "\n",
    "def recalc_cluster(cluster):\n",
    "    m = len(cluster[0])\n",
    "    center = [0] * m\n",
    "    for point in cluster:\n",
    "        for i in range(m):\n",
    "            center[i] += point[i]\n",
    "    center = [x / len(cluster) for x in center]\n",
    "    return center\n",
    "\n",
    "def dist_dis(p1,p2):\n",
    "    return sum([(p1[i]-p2[i])**2 for i in range(len(p1))])\n",
    "\n",
    "\n",
    "def LloydAlgorithm(data, k, n, m):\n",
    "    all_centers = []\n",
    "    for i in range(k):\n",
    "        all_centers.append(data[i])\n",
    "\n",
    "#     print((all_centers))\n",
    "    \n",
    "    while True:\n",
    "        cluster_dict = defaultdict(list)\n",
    "        re_clusters = [[]] * k\n",
    "        for p1 in data:\n",
    "#             print(p1)\n",
    "#             print(pt_center(p1, all_centers))\n",
    "            cluster_dict[tuple(pt_center(p1, all_centers))].append(p1)\n",
    "        for i in range(k):\n",
    "            re_clusters[i] = recalc_cluster(cluster_dict[tuple(all_centers[i])])\n",
    "        if re_clusters == all_centers:\n",
    "            break\n",
    "        all_centers = re_clusters\n",
    "\n",
    "    return all_centers\n",
    "\n",
    "def main():\n",
    "    \n",
    "    with open('/Users/nises/Downloads/dataset_604539_3.txt', 'r') as f:\n",
    "        km = f.readline().strip().split(' ')\n",
    "        mat_a = [[float(num) for num in line.strip().split(' ')] for line in f]\n",
    "        \n",
    "    k = int(km[0])\n",
    "    m = int(km[1])\n",
    "    n = (len(mat_a))\n",
    "    print(k)\n",
    "    print(m)\n",
    "    print(n)\n",
    "#     print(mat_a)\n",
    "    cet = LloydAlgorithm(mat_a, k, n, m)\n",
    "    for center in cet:\n",
    "        print(\" \".join(map(str, center)))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e35e14",
   "metadata": {},
   "source": [
    "# 6.14 STEP 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b359382c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19]]\n",
      "4 15\n",
      "1 6\n",
      "2 8\n",
      "13 17\n",
      "14 18\n",
      "3 16\n",
      "11 12\n",
      "9 4 15\n",
      "7 1 6\n",
      "10 2 8\n",
      "5 10 2 8\n",
      "13 17 3 16\n",
      "11 12 9 4 15\n",
      "19 5 10 2 8\n",
      "7 1 6 13 17 3 16\n",
      "20 11 12 9 4 15\n",
      "14 18 20 11 12 9 4 15\n",
      "19 5 10 2 8 14 18 20 11 12 9 4 15\n",
      "7 1 6 13 17 3 16 19 5 10 2 8 14 18 20 11 12 9 4 15\n"
     ]
    }
   ],
   "source": [
    "# HierarchicalClustering(D, n)\n",
    "#     Clusters ← n single-element clusters labeled 1, ... , n \n",
    "#      construct a graph T with n isolated nodes labeled by single elements 1, ... , n \n",
    "#     while there is more than one cluster \n",
    "#         find the two closest clusters Ci and Cj ",
    " \n",
    "#         merge Ci and Cj into a new cluster Cnew with |Ci| + |Cj| elements\n",
    "#         add a new node labeled by cluster Cnew to T\n",
    "#         connect node Cnew to Ci and Cj by directed edges ",
    "\n",
    "#         remove the rows and columns of D corresponding to Ci and Cj ",
    "\n",
    "#         remove Ci and Cj from Clusters ",
    "\n",
    "#         add a row/column to D for Cnew by computing D(Cnew, C) for each C in Clusters \n",
    "#         add Cnew to Clusters \n",
    "#     assign root in T as a node with no incoming edges\n",
    "#     return T\n",
    "\n",
    "def HierarchicalClustering(distance_matrix, n):\n",
    "    clusters = [[i] for i in range(len(distance_matrix))]\n",
    "    \n",
    "    print(clusters)\n",
    "\n",
    "    new_clusters_list = []\n",
    "    while len(clusters) > 1:\n",
    "\n",
    "        min_dist = float('inf')\n",
    "        for i in range(len(clusters) - 1):\n",
    "            for j in range(i + 1, len(clusters)):\n",
    "                dist = 0\n",
    "                for idx1 in clusters[i]:\n",
    "                    for idx2 in clusters[j]:\n",
    "                        dist += distance_matrix[idx1][idx2]\n",
    "                dist /= (len(clusters[i]) * len(clusters[j]))\n",
    "                    \n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    closest_idx1 = i\n",
    "                    closest_idx2 = j\n",
    "\n",
    "        new_cluster = clusters[closest_idx1] + clusters[closest_idx2]\n",
    "        clusters = [clu for clu in clusters if clu not in [clusters[closest_idx1], clusters[closest_idx2]]]\n",
    "        clusters.append(new_cluster)\n",
    "        new_clusters_list.append(new_cluster)\n",
    "    return new_clusters_list\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    with open('/Users/nises/Downloads/dataset_604545_7.txt', 'r') as f:\n",
    "        n = f.readline().strip().split(' ')\n",
    "        dist_m = [[float(num) for num in line.strip().split(' ')] for line in f]\n",
    "        \n",
    "#     print(n)\n",
    "#     print(dist_m)\n",
    "    n = n[0]\n",
    "    h_cluster = HierarchicalClustering(dist_m, n)\n",
    "    \n",
    "    for each in h_cluster:\n",
    "        print(' '.join([str(x + 1) for x in each]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d77f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a427d21",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
